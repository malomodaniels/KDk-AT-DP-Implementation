{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvtx04ClCXNs",
        "outputId": "7a773be6-77d5-42ce-9163-2048a2fc68f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "PyTorch CUDA available: True\n",
            "Current CUDA device: 0\n",
            "CUDA device count: 1\n",
            "Device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "cuDNN benchmark enabled for GPU performance.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 – Mount Drive | Imports | Seed | CONFIG\n",
        "from pathlib import Path\n",
        "import os, time, math, pickle, random, warnings\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.optim as optim, torch.nn.functional as F\n",
        "from tqdm import tqdm  # Add tqdm for progress tracking\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Mount Google Drive (if available)\n",
        "def in_colab():\n",
        "    try:\n",
        "        import google.colab  # noqa\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "# Reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# CONFIG\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
        "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "\n",
        "CONFIG = {\n",
        "    \"DEVICE\": DEVICE,\n",
        "    \"SEED\": 42,\n",
        "    \"NUM_WORKERS\": 0,  # Keep at 0 for Colab\n",
        "    \"BATCH_SIZE\": 32 if DEVICE == \"cpu\" else 64,\n",
        "    \"LR\": 1e-3,\n",
        "    \"DEFAULT_EPOCHS\": 30,\n",
        "    \"EPOCHS_PER_DATASET\": {\"CIFAR10\": 15, \"CIFAR100\": 30, \"CINIC10\": 30},\n",
        "    \"KD_TEMPERATURE\": 4.0,\n",
        "    \"KD_LAMBDA\": 0.7,\n",
        "    \"AT_PGD_STEPS\": 5,\n",
        "    \"AT_STEP_SIZE\": 2/255,\n",
        "    \"AUX_SIZE\": 1000,\n",
        "    \"DATASET_HP\": {\n",
        "        \"CIFAR10\":  {\"tau\": 4.0, \"k\": 3, \"eps_k\": 0.15, \"lr_teacher\": 1e-3, \"lr_student\": 5e-4, \"adv_eps\": 8/255},\n",
        "        \"CIFAR100\": {\"tau\": 5.0, \"k\": 5, \"eps_k\": 0.15, \"lr_teacher\": 1e-3, \"lr_student\": 5e-4, \"adv_eps\": 8/255},\n",
        "        \"CINIC10\":  {\"tau\": 3.5, \"k\": 3, \"eps_k\": 0.15, \"lr_teacher\": 1e-3, \"lr_student\": 5e-4, \"adv_eps\": 8/255}\n",
        "    },\n",
        "    \"SIZES\": {\n",
        "        \"CIFAR10\":  (50_000, 10_000),\n",
        "        \"CIFAR100\": (50_000, 10_000),\n",
        "        \"CINIC10\":  (90_000, 90_000),\n",
        "        \"YAHOO\":    (50_000, 20_000),\n",
        "        \"CRITEO\":   (80_000, 20_000)\n",
        "    },\n",
        "    \"CLAMP_MIN\": -3.0,\n",
        "    \"CLAMP_MAX\":  3.0,\n",
        "    \"DRIVE_PATH\": \"/content\",\n",
        "    \"PIN_MEMORY\": False,\n",
        "    \"PREFETCH_FACTOR\": None,\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG[\"DRIVE_PATH\"], exist_ok=True)\n",
        "print(\"Device:\", CONFIG[\"DEVICE\"])\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f} GB\")\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    print(\"cuDNN benchmark enabled for GPU performance.\")\n",
        "else:\n",
        "    print(\"WARNING: Running on CPU - training will be slow!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 – Transforms | Dataset Loading | Downsampling | Vertical Split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10, CIFAR100, ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import zipfile, random, shutil\n",
        "\n",
        "# Normalization & Augmentation\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "train_tf_32 = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "test_tf_32 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "train_tf_cinic = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "test_tf_cinic = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# --- Channel Split for VFL ---\n",
        "def image_channel_split(x):\n",
        "    c1, c2, c3 = x.chunk(3, dim=1)\n",
        "    return c1, torch.cat([c2, c3], dim=1)\n",
        "\n",
        "class VertImageLoader:\n",
        "    def __init__(self, base_loader): self.base_loader = base_loader\n",
        "    def __iter__(self):\n",
        "        for imgs, y in self.base_loader:\n",
        "            xa, xp = image_channel_split(imgs)\n",
        "            yield (xa, xp), y\n",
        "    def __len__(self): return len(self.base_loader)\n",
        "\n",
        "# Local Dataset Path\n",
        "DATA_PATH = Path(\"/content/datasets\")\n",
        "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy archives from Drive if needed\n",
        "drive_ds = Path(\"/content/drive/MyDrive/datasets\")\n",
        "if drive_ds.exists():\n",
        "    for z in drive_ds.glob(\"*.zip\"):\n",
        "        dest = DATA_PATH / z.name\n",
        "        if not dest.exists():\n",
        "            print(f\"Copying {z.name} to local disk for speed...\")\n",
        "            shutil.copy(z, dest)\n",
        "\n",
        "# Disable multiprocessing for Colab (prevents 1st-epoch stall)\n",
        "CONFIG[\"NUM_WORKERS\"] = 0\n",
        "CONFIG[\"PREFETCH_FACTOR\"] = None\n",
        "CONFIG[\"PIN_MEMORY\"] = False\n",
        "\n",
        "def create_dataloader(ds, bs, shuffle):\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=0,\n",
        "        pin_memory=False,\n",
        "        persistent_workers=False,\n",
        "        drop_last=shuffle\n",
        "    )\n",
        "\n",
        "def subsample_dataset(dataset, target_size, seed=42):\n",
        "    random.seed(seed)\n",
        "    total = len(dataset)\n",
        "    if target_size < total:\n",
        "        indices = random.sample(range(total), target_size)\n",
        "        dataset = Subset(dataset, indices)\n",
        "    return dataset\n",
        "\n",
        "VISION_LOADERS = {}\n",
        "\n",
        "# CIFAR-10\n",
        "print(\"Preparing CIFAR10 ...\")\n",
        "tr = CIFAR10(DATA_PATH, train=True, download=True, transform=train_tf_32)\n",
        "te = CIFAR10(DATA_PATH, train=False, download=True, transform=test_tf_32)\n",
        "t_train, t_test = CONFIG[\"SIZES\"][\"CIFAR10\"]\n",
        "tr, te = subsample_dataset(tr, t_train), subsample_dataset(te, t_test)\n",
        "VISION_LOADERS[\"CIFAR10\"] = {\n",
        "    \"train\": VertImageLoader(create_dataloader(tr, CONFIG[\"BATCH_SIZE\"], True)),\n",
        "    \"test\":  VertImageLoader(create_dataloader(te, CONFIG[\"BATCH_SIZE\"], False)),\n",
        "    \"num_classes\": 10,\n",
        "}\n",
        "print(f\" CIFAR10 → train={t_train}, test={t_test}\")\n",
        "\n",
        "# CIFAR-100\n",
        "print(\"Preparing CIFAR100 ...\")\n",
        "tr = CIFAR100(DATA_PATH, train=True, download=True, transform=train_tf_32)\n",
        "te = CIFAR100(DATA_PATH, train=False, download=True, transform=test_tf_32)\n",
        "t_train, t_test = CONFIG[\"SIZES\"][\"CIFAR100\"]\n",
        "tr, te = subsample_dataset(tr, t_train), subsample_dataset(te, t_test)\n",
        "VISION_LOADERS[\"CIFAR100\"] = {\n",
        "    \"train\": VertImageLoader(create_dataloader(tr, CONFIG[\"BATCH_SIZE\"], True)),\n",
        "    \"test\":  VertImageLoader(create_dataloader(te, CONFIG[\"BATCH_SIZE\"], False)),\n",
        "    \"num_classes\": 100,\n",
        "}\n",
        "print(f\" CIFAR100 → train={t_train}, test={t_test}\")\n",
        "\n",
        "# CINIC-10 (Flexible Extraction + Path Normalization)\n",
        "print(\"Preparing CINIC10 ...\")\n",
        "cinic_root = DATA_PATH / \"cinic-10\"\n",
        "alt_root   = DATA_PATH / \"CINIC-10\"\n",
        "cinic_zip  = DATA_PATH / \"cinic-10.zip\"\n",
        "\n",
        "# Extract if needed\n",
        "if not cinic_root.exists() and alt_root.exists():\n",
        "    cinic_root = alt_root\n",
        "if not cinic_root.exists() and cinic_zip.exists():\n",
        "    print(f\" Extracting CINIC-10 from {cinic_zip} ...\")\n",
        "    with zipfile.ZipFile(cinic_zip, \"r\") as zf:\n",
        "        zf.extractall(DATA_PATH)\n",
        "    cinic_root = DATA_PATH / \"cinic-10\"\n",
        "\n",
        "# Load if available\n",
        "if cinic_root.exists():\n",
        "    cinic_tr = ImageFolder(cinic_root/\"train\", transform=train_tf_cinic)\n",
        "    cinic_te = ImageFolder(cinic_root/\"test\",  transform=test_tf_cinic)\n",
        "    t_train, t_test = CONFIG[\"SIZES\"][\"CINIC10\"]\n",
        "    cinic_tr, cinic_te = subsample_dataset(cinic_tr, t_train), subsample_dataset(cinic_te, t_test)\n",
        "    VISION_LOADERS[\"CINIC10\"] = {\n",
        "        \"train\": VertImageLoader(create_dataloader(cinic_tr, CONFIG[\"BATCH_SIZE\"], True)),\n",
        "        \"test\":  VertImageLoader(create_dataloader(cinic_te, CONFIG[\"BATCH_SIZE\"], False)),\n",
        "        \"num_classes\": 10,\n",
        "    }\n",
        "    print(f\" CINIC10 → train={t_train}, test={t_test}\")\n",
        "else:\n",
        "    print(\" CINIC-10 dataset not found — skipped.\")\n",
        "\n",
        "print(\"\\nAll vision datasets preloaded and downsampled successfully (Colab-safe).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEYivLfGCZNe",
        "outputId": "8abbb320-39ef-4b4d-f33e-3e847a47812f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying criteo.zip to local disk for speed...\n",
            "Copying cinic-10.zip to local disk for speed...\n",
            "Preparing CIFAR10 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:11<00:00, 14.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CIFAR10 → train=50000, test=10000\n",
            "Preparing CIFAR100 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:11<00:00, 14.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CIFAR100 → train=50000, test=10000\n",
            "Preparing CINIC10 ...\n",
            " Extracting CINIC-10 from /content/datasets/cinic-10.zip ...\n",
            " CINIC10 → train=90000, test=90000\n",
            "\n",
            "All vision datasets preloaded and downsampled successfully (Colab-safe).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 – VFL Vision Model Definitions\n",
        "class BottomModelA_Vision(nn.Module):\n",
        "    def __init__(self, out_dim=512):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64,128,3,padding=1,bias=False), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128,128,3,padding=1,bias=False), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128,256,3,padding=1,bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256,256,3,padding=1,bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.Linear(256,out_dim), nn.BatchNorm1d(out_dim),\n",
        "                                nn.ReLU(inplace=True), nn.Dropout(0.2))\n",
        "    def forward(self,x):\n",
        "        h=self.features(x).view(x.size(0),-1)\n",
        "        return self.fc(h)\n",
        "\n",
        "class BottomModelP_Vision(BottomModelA_Vision):\n",
        "    def __init__(self,out_dim=512):\n",
        "        super().__init__(out_dim)\n",
        "        self.features[0]=nn.Conv2d(2,64,3,padding=1,bias=False)\n",
        "\n",
        "class TopModel_Vision(nn.Module):\n",
        "    def __init__(self,num_classes,in_dim=1024):\n",
        "        super().__init__()\n",
        "        self.fc1, self.bn1 = nn.Linear(in_dim,512), nn.BatchNorm1d(512)\n",
        "        self.fc2, self.bn2 = nn.Linear(512,256), nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256,num_classes)\n",
        "    def forward(self,h_a,h_p):\n",
        "        h=torch.cat([h_a,h_p],dim=1)\n",
        "        h=F.relu(self.bn1(self.fc1(h)))\n",
        "        h=F.relu(self.bn2(self.fc2(h)))\n",
        "        return self.fc3(h)\n",
        "\n",
        "class VFLModel(nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "        super().__init__()\n",
        "        self.bottom_a=BottomModelA_Vision()\n",
        "        self.bottom_p=BottomModelP_Vision()\n",
        "        self.top_model=TopModel_Vision(num_classes)\n",
        "    def forward(self,x_a,x_p):\n",
        "        return self.top_model(self.bottom_a(x_a), self.bottom_p(x_p))\n",
        "\n",
        "def build_vfl_model_vision(num_classes:int):\n",
        "    model=VFLModel(num_classes)\n",
        "    for m in model.modules():\n",
        "        if isinstance(m,nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
        "        elif isinstance(m,(nn.BatchNorm2d,nn.BatchNorm1d)):\n",
        "            nn.init.constant_(m.weight,1); nn.init.constant_(m.bias,0)\n",
        "        elif isinstance(m,nn.Linear):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None: nn.init.constant_(m.bias,0)\n",
        "    return model.to(CONFIG[\"DEVICE\"])\n"
      ],
      "metadata": {
        "id": "mdgDY8lfCZQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 – VFL Training and Evaluation Functions\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_epoch_OA(model, loader, optimizer, config, dataset, use_at=False, show_progress=True):\n",
        "    \"\"\"\n",
        "    Trains the main VFL model (e.g., the teacher 'OA') for one epoch.\n",
        "    Returns training loss and training accuracy.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "    iterator = tqdm(loader, desc='Training OA', ncols=100) if show_progress else loader\n",
        "    device = config[\"DEVICE\"]\n",
        "\n",
        "    for (xa, xp), y in iterator:\n",
        "        xa, xp, y = xa.to(device), xp.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xa, xp)\n",
        "        loss = F.cross_entropy(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        total_correct += (preds == y).sum().item()\n",
        "        total_samples += y.size(0)\n",
        "\n",
        "        if show_progress:\n",
        "            iterator.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    train_acc = 100.0 * total_correct / total_samples\n",
        "    return avg_loss, train_acc\n",
        "\n",
        "def train_epoch_KD(student, teacher, loader, optimizer, config, dataset_name, use_at=False, show_progress=True):\n",
        "    \"\"\"\n",
        "    Trains a VFL student model using knowledge distillation.\n",
        "    Returns training loss and training accuracy.\n",
        "    \"\"\"\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "    iterator = tqdm(loader, desc='Training KD', ncols=100) if show_progress else loader\n",
        "    device = config[\"DEVICE\"]\n",
        "    hp = config[\"DATASET_HP\"][dataset_name]\n",
        "\n",
        "    for (xa, xp), y in iterator:\n",
        "        xa, xp, y = xa.to(device), xp.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        xp_train = xp\n",
        "        if use_at:\n",
        "            student.eval()\n",
        "            xp_adv = xp.clone().detach().requires_grad_(True)\n",
        "            logits_adv = student(xa, xp_adv)\n",
        "            loss_adv = F.cross_entropy(logits_adv, y)\n",
        "            grad = torch.autograd.grad(loss_adv, xp_adv, retain_graph=False)[0]\n",
        "            student.train()\n",
        "            xp_train = torch.clamp(xp + hp[\"adv_eps\"] * grad.sign(), config[\"CLAMP_MIN\"], config[\"CLAMP_MAX\"]).detach()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher(xa, xp_train)\n",
        "        student_logits = student(xa, xp_train)\n",
        "\n",
        "        T = hp[\"tau\"]\n",
        "        kd_loss = F.kl_div(F.log_softmax(student_logits / T, dim=1), F.log_softmax(teacher_logits / T, dim=1), reduction='batchmean', log_target=True) * (T * T)\n",
        "        ce_loss = F.cross_entropy(student_logits, y)\n",
        "        loss = config[\"KD_LAMBDA\"] * kd_loss + (1 - config[\"KD_LAMBDA\"]) * ce_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        preds = student_logits.argmax(1)\n",
        "        total_correct += (preds == y).sum().item()\n",
        "        total_samples += y.size(0)\n",
        "\n",
        "        if show_progress and (iterator.n % 50 == 0):\n",
        "             iterator.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    train_acc = 100.0 * total_correct / total_samples\n",
        "    return avg_loss, train_acc\n",
        "\n",
        "def train_epoch_KD_DP(student, teacher, loader, optimizer, config, dataset_name, noise_multiplier=0.5, use_at=True, show_progress=True):\n",
        "    \"\"\"\n",
        "    Trains a student with KD and AT, adding noise to the passive party's\n",
        "    gradient using a hook for improved privacy and lower ASR. (CORRECTED)\n",
        "    \"\"\"\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "    device = config[\"DEVICE\"]\n",
        "    hp = config[\"DATASET_HP\"][dataset_name]\n",
        "    iterator = tqdm(loader, desc='Training KD+AT+DP', ncols=100) if show_progress else loader\n",
        "\n",
        "    for (xa, xp), y in iterator:\n",
        "        xa, xp, y = xa.to(device), xp.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        xp_train = xp\n",
        "        if use_at:\n",
        "            student.eval()\n",
        "            xp_adv = xp.clone().detach().requires_grad_(True)\n",
        "            logits_adv = student(xa, xp_adv)\n",
        "            loss_adv = F.cross_entropy(logits_adv, y)\n",
        "            grad = torch.autograd.grad(loss_adv, xp_adv, retain_graph=False)[0]\n",
        "            student.train()\n",
        "            xp_train = torch.clamp(xp + hp[\"adv_eps\"] * grad.sign(), config[\"CLAMP_MIN\"], config[\"CLAMP_MAX\"]).detach()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher(xa, xp_train)\n",
        "\n",
        "        h_a = student.bottom_a(xa)\n",
        "        h_p = student.bottom_p(xp_train)\n",
        "\n",
        "        if noise_multiplier > 0:\n",
        "            def add_noise_hook(grad):\n",
        "                noise = torch.randn_like(grad) * noise_multiplier\n",
        "                return grad + noise\n",
        "            h_p.register_hook(add_noise_hook)\n",
        "\n",
        "        student_logits = student.top_model(h_a, h_p)\n",
        "\n",
        "        T = hp[\"tau\"]\n",
        "        kd_loss = F.kl_div(F.log_softmax(student_logits / T, dim=1), F.log_softmax(teacher_logits / T, dim=1), reduction='batchmean', log_target=True) * (T * T)\n",
        "        ce_loss = F.cross_entropy(student_logits, y)\n",
        "        loss = config[\"KD_LAMBDA\"] * kd_loss + (1 - config[\"KD_LAMBDA\"]) * ce_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        preds = student_logits.argmax(1)\n",
        "        total_correct += (preds == y).sum().item()\n",
        "        total_samples += y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
        "    train_acc = 100.0 * total_correct / total_samples if total_samples > 0 else 0.0\n",
        "    return avg_loss, train_acc\n",
        "\n",
        "print(\"All VFL training functions loaded successfully (including hook-based DP).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et4O8iYrCZTn",
        "outputId": "28cccbc8-97ba-4917-a853-d1549e01f690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All VFL training functions loaded successfully (including hook-based DP).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 – Evaluation and Privacy Attack Functions\n",
        "from sklearn.metrics import f1_score, roc_auc_score, top_k_accuracy_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate_model(model, loader, config, robust=False, dataset_name=None):\n",
        "    \"\"\"\n",
        "    Compute loss, Top-1, and Top-5 accuracy for VFL models.\n",
        "    This version correctly returns THREE values: (loss, top1_acc, top5_acc).\n",
        "    \"\"\"\n",
        "    device = config[\"DEVICE\"]\n",
        "    model.eval()\n",
        "    y_true_list, y_probs_list = [], []\n",
        "    total_loss, total = 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (xa, xp), y in loader:\n",
        "            xa, xp, y = xa.to(device), xp.to(device), y.to(device)\n",
        "            xp_eval = xp\n",
        "\n",
        "            if robust:\n",
        "                with torch.enable_grad():\n",
        "                    hp = config[\"DATASET_HP\"][dataset_name]\n",
        "                    eps = hp[\"adv_eps\"]\n",
        "                    xp_adv = xp.clone().detach().requires_grad_(True)\n",
        "                    logits_adv = model(xa, xp_adv)\n",
        "                    loss_adv = F.cross_entropy(logits_adv, y)\n",
        "                    grad = torch.autograd.grad(loss_adv, xp_adv, retain_graph=False)[0]\n",
        "                xp_eval = torch.clamp(xp + eps * grad.sign(), config[\"CLAMP_MIN\"], config[\"CLAMP_MAX\"])\n",
        "\n",
        "            logits = model(xa, xp_eval)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            total_loss += loss.item() * y.size(0)\n",
        "            total += y.size(0)\n",
        "\n",
        "            y_true_list.extend(y.cpu().numpy())\n",
        "            y_probs_list.extend(F.softmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "    loss_avg = total_loss / total if total > 0 else 0.0\n",
        "    y_true = np.array(y_true_list)\n",
        "    y_probs = np.array(y_probs_list)\n",
        "\n",
        "    # Calculate Top-1 and Top-5 accuracy\n",
        "    num_classes = y_probs.shape[1]\n",
        "    top1_acc = top_k_accuracy_score(y_true, y_probs, k=1, labels=range(num_classes)) * 100\n",
        "    top5_acc = top_k_accuracy_score(y_true, y_probs, k=min(5, num_classes), labels=range(num_classes)) * 100\n",
        "\n",
        "    return loss_avg, top1_acc, top5_acc\n",
        "\n",
        "\n",
        "def run_privacy_attack_vision_multimode(\n",
        "    vfl_model, train_loader, test_loader, config, num_classes,\n",
        "    attack_type=\"passive\", aux_batches_limit=4,\n",
        "    attacker_lr=5e-4, attacker_epochs=2,\n",
        "    active_eps=0.02, active_queries=2, perturbed_sigma=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    Multi-mode Label Inference Attack. Returns both Top-1 and Top-5 ASR.\n",
        "    \"\"\"\n",
        "    device = config[\"DEVICE\"]\n",
        "    vfl_model.eval()\n",
        "\n",
        "    (xa_ex, xp_ex), _ = next(iter(test_loader))\n",
        "    with torch.no_grad():\n",
        "        h_p_dim = vfl_model.bottom_p(xp_ex[:1].to(device)).shape[1]\n",
        "\n",
        "    feat_dim = h_p_dim * active_queries if attack_type == \"active\" else h_p_dim\n",
        "    attacker = nn.Sequential(\n",
        "        nn.Linear(feat_dim, 128), nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2), nn.Linear(128, num_classes)\n",
        "    ).to(device)\n",
        "    opt = torch.optim.AdamW(attacker.parameters(), lr=attacker_lr, weight_decay=1e-4)\n",
        "\n",
        "    aux_data = []\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        if i >= aux_batches_limit: break\n",
        "        aux_data.append(batch)\n",
        "\n",
        "    # Train Attacker\n",
        "    attacker.train()\n",
        "    for _ in range(attacker_epochs):\n",
        "        for (xa, xp), y in aux_data:\n",
        "            xa, xp, y = xa.to(device), xp.to(device), y.to(device)\n",
        "            with torch.enable_grad():\n",
        "                if attack_type == \"direct\":\n",
        "                    feat = vfl_model.bottom_p(xp)\n",
        "                elif attack_type == \"active\":\n",
        "                    grads = []\n",
        "                    h_a = vfl_model.bottom_a(xa)\n",
        "                    for _ in range(active_queries):\n",
        "                        delta = (torch.rand_like(xp) * 2 - 1) * active_eps\n",
        "                        xp_q = torch.clamp(xp + delta, config[\"CLAMP_MIN\"], config[\"CLAMP_MAX\"])\n",
        "                        h_p_q = vfl_model.bottom_p(xp_q); h_p_q.requires_grad_()\n",
        "                        logits_q = vfl_model.top_model(h_a, h_p_q)\n",
        "                        grad_q = torch.autograd.grad(logits_q.sum(), h_p_q, retain_graph=False)[0]\n",
        "                        grads.append(grad_q)\n",
        "                    feat = torch.cat(grads, dim=1)\n",
        "                else: # Passive and Perturbed\n",
        "                    h_p = vfl_model.bottom_p(xp); h_p.requires_grad_()\n",
        "                    h_a = vfl_model.bottom_a(xa)\n",
        "                    logits = vfl_model.top_model(h_a, h_p)\n",
        "                    grad = torch.autograd.grad(logits.sum(), h_p, retain_graph=False)[0]\n",
        "                    if attack_type == \"passive\":\n",
        "                        feat = grad\n",
        "                    elif attack_type == \"perturbed\":\n",
        "                        feat = grad + torch.randn_like(grad) * perturbed_sigma\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            pred = attacker(feat.detach())\n",
        "            loss = F.cross_entropy(pred, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    # Evaluate Attacker\n",
        "    attacker.eval()\n",
        "    y_true, y_probs = [], []\n",
        "    with torch.no_grad():\n",
        "        for (xa, xp), y in test_loader:\n",
        "            xa, xp, y = xa.to(device), xp.to(device), y.to(device)\n",
        "            with torch.enable_grad():\n",
        "                if attack_type == \"direct\":\n",
        "                    feat = vfl_model.bottom_p(xp)\n",
        "                elif attack_type == \"active\":\n",
        "                    grads = []\n",
        "                    h_a = vfl_model.bottom_a(xa)\n",
        "                    for _ in range(active_queries):\n",
        "                        delta = (torch.rand_like(xp) * 2 - 1) * active_eps\n",
        "                        xp_q = torch.clamp(xp + delta, config[\"CLAMP_MIN\"], config[\"CLAMP_MAX\"])\n",
        "                        h_p_q = vfl_model.bottom_p(xp_q); h_p_q.requires_grad_()\n",
        "                        logits_q = vfl_model.top_model(h_a, h_p_q)\n",
        "                        grad_q = torch.autograd.grad(logits_q.sum(), h_p_q, retain_graph=False)[0]\n",
        "                        grads.append(grad_q)\n",
        "                    feat = torch.cat(grads, dim=1)\n",
        "                else: # Passive and Perturbed\n",
        "                    h_p = vfl_model.bottom_p(xp); h_p.requires_grad_()\n",
        "                    h_a = vfl_model.bottom_a(xa)\n",
        "                    logits = vfl_model.top_model(h_a, h_p)\n",
        "                    grad = torch.autograd.grad(logits.sum(), h_p, retain_graph=False)[0]\n",
        "                    if attack_type == \"passive\":\n",
        "                        feat = grad\n",
        "                    elif attack_type == \"perturbed\":\n",
        "                        feat = grad\n",
        "            probs = F.softmax(attacker(feat.detach()), dim=1).cpu()\n",
        "            y_true.extend(y.cpu().tolist()); y_probs.extend(probs.tolist())\n",
        "\n",
        "    y_true, y_probs = np.array(y_true), np.array(y_probs)\n",
        "\n",
        "    # Calculate Top-1 and Top-5 ASR\n",
        "    asr_top1 = top_k_accuracy_score(y_true, y_probs, k=1, labels=range(num_classes)) * 100\n",
        "    asr_top5 = top_k_accuracy_score(y_true, y_probs, k=min(5, num_classes), labels=range(num_classes)) * 100\n",
        "\n",
        "    return float(asr_top1), float(asr_top5)\n",
        "\n",
        "print(\"Functions updated to return Evaluation Metrics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtpiPEpNCZWo",
        "outputId": "7fe1f7d5-6795-432e-ac84-5663dcc2f6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions updated to return Evaluation Metrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 – Main Vision Training Loop\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from pathlib import Path\n",
        "\n",
        "VISION_GROUP = [\"CIFAR10\"]\n",
        "SAVED_MODELS_VISION, VISION_TRAIN_LOGS = {}, []\n",
        "\n",
        "drive_results_dir = Path(CONFIG[\"DRIVE_PATH\"]) / \"VFL_Results\" / \"VISION\"\n",
        "drive_results_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Starting Vision VFL Training with Optimizations\\n\" + \"=\"*70)\n",
        "\n",
        "for dataset_name in VISION_GROUP:\n",
        "    if dataset_name not in VISION_LOADERS:\n",
        "        print(f\"Skipping {dataset_name} (not loaded)\")\n",
        "        continue\n",
        "\n",
        "    loaders = VISION_LOADERS[dataset_name]\n",
        "    tr_loader, te_loader = loaders[\"train\"], loaders[\"test\"]\n",
        "    num_classes = loaders[\"num_classes\"]\n",
        "    epochs = CONFIG[\"EPOCHS_PER_DATASET\"].get(dataset_name, CONFIG[\"DEFAULT_EPOCHS\"])\n",
        "    hp = CONFIG[\"DATASET_HP\"][dataset_name]\n",
        "    SAVED_MODELS_VISION[dataset_name] = {}\n",
        "\n",
        "    # Phase 1: Original Architecture OA/Teacher\n",
        "    print(f\"\\n{dataset_name} – Phase 1: Training OA (Teacher)\")\n",
        "    OA = build_vfl_model_vision(num_classes)\n",
        "    opt = optim.AdamW(OA.parameters(), lr=hp[\"lr_teacher\"], weight_decay=1e-4)\n",
        "    sched = CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-5)\n",
        "    best_val, no_imp, patience = 0, 0, 5\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        t0 = time.perf_counter()\n",
        "        train_loss, train_acc = train_epoch_OA(OA, tr_loader, opt, CONFIG, dataset=dataset_name, show_progress=True)\n",
        "        sched.step()\n",
        "        val_loss, val_acc = evaluate_model(OA, te_loader, CONFIG, dataset_name=dataset_name)\n",
        "        elapsed = time.perf_counter() - t0\n",
        "        print(f\"  Epoch {ep+1:02d}/{epochs} | Train Loss={train_loss:.4f} | Train ACC={train_acc:6.2f}% | Val Loss={val_loss:.4f} | Val ACC={val_acc:6.2f}% | Time={elapsed:.1f}s\")\n",
        "        if val_acc > best_val:\n",
        "            best_val, no_imp = val_acc, 0\n",
        "            torch.save(OA.state_dict(), drive_results_dir / f\"{dataset_name}_OA_best.pth\")\n",
        "            print(f\"    → Best model saved (Val ACC: {val_acc:.2f}%)\")\n",
        "        else:\n",
        "            no_imp += 1\n",
        "            if no_imp >= patience:\n",
        "                print(\"  Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    OA.load_state_dict(torch.load(drive_results_dir / f\"{dataset_name}_OA_best.pth\", map_location=CONFIG[\"DEVICE\"]))\n",
        "    SAVED_MODELS_VISION[dataset_name][\"OA\"] = f\"{dataset_name}_OA_best.pth\"\n",
        "\n",
        "    # Phase 2: Knowledge Distillation (KD) with k-anonymity\n",
        "    print(f\"\\n{dataset_name} – Phase 2: Training KDk (Student)\")\n",
        "    KDk = build_vfl_model_vision(num_classes)\n",
        "    opt = optim.AdamW(KDk.parameters(), lr=hp[\"lr_student\"], weight_decay=1e-4)\n",
        "    sched = CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-6)\n",
        "    best_val, no_imp = 0, 0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        t0 = time.perf_counter()\n",
        "        train_loss, train_acc = train_epoch_KD(KDk, OA, tr_loader, opt, CONFIG, dataset_name, show_progress=True)\n",
        "        sched.step()\n",
        "        val_loss, val_acc = evaluate_model(KDk, te_loader, CONFIG, dataset_name=dataset_name)\n",
        "        elapsed = time.perf_counter() - t0\n",
        "        print(f\"  Epoch {ep+1:02d}/{epochs} | Train Loss={train_loss:.4f} | Train ACC={train_acc:6.2f}% | Val Loss={val_loss:.4f} | Val ACC={val_acc:6.2f}% | Time={elapsed:.1f}s\")\n",
        "        if val_acc > best_val:\n",
        "            best_val, no_imp = val_acc, 0\n",
        "            torch.save(KDk.state_dict(), drive_results_dir / f\"{dataset_name}_KDk_best.pth\")\n",
        "            print(f\"    → Best model saved (Val ACC: {val_acc:.2f}%)\")\n",
        "        else:\n",
        "            no_imp += 1\n",
        "            if no_imp >= patience:\n",
        "                print(\"  Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    KDk.load_state_dict(torch.load(drive_results_dir / f\"{dataset_name}_KDk_best.pth\", map_location=CONFIG[\"DEVICE\"]))\n",
        "    SAVED_MODELS_VISION[dataset_name][\"KDk\"] = f\"{dataset_name}_KDk_best.pth\"\n",
        "\n",
        "    # Phase 3: KDk with Adversarial Training (KDk+AT)\n",
        "    print(f\"\\n{dataset_name} – Phase 3: Training KDk+AT (Student + Adv Train)\")\n",
        "    KDkAT = build_vfl_model_vision(num_classes)\n",
        "    opt = optim.AdamW(KDkAT.parameters(), lr=hp[\"lr_student\"], weight_decay=1e-4)\n",
        "    sched = CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-6)\n",
        "    best_rob, no_imp = 0, 0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        t0 = time.perf_counter()\n",
        "        train_loss, train_acc = train_epoch_KD(KDkAT, OA, tr_loader, opt, CONFIG, dataset_name, use_at=True, show_progress=True)\n",
        "        sched.step()\n",
        "        val_loss, val_acc = evaluate_model(KDkAT, te_loader, CONFIG, dataset_name=dataset_name)\n",
        "        _, rob_acc = evaluate_model(KDkAT, te_loader, CONFIG, robust=True, dataset_name=dataset_name)\n",
        "        elapsed = time.perf_counter() - t0\n",
        "        print(f\"  Epoch {ep+1:02d}/{epochs} | Train Loss={train_loss:.4f} | Train ACC={train_acc:6.2f}% | Val Loss={val_loss:.4f} | Val ACC={val_acc:6.2f}% | Robust={rob_acc:6.2f}% | Time={elapsed:.1f}s\")\n",
        "        if rob_acc > best_rob:\n",
        "            best_rob, no_imp = rob_acc, 0\n",
        "            torch.save(KDkAT.state_dict(), drive_results_dir / f\"{dataset_name}_KDkAT_best.pth\")\n",
        "            print(f\"    → Best model saved (Robust ACC: {rob_acc:.2f}%)\")\n",
        "        else:\n",
        "            no_imp += 1\n",
        "            if no_imp >= patience:\n",
        "                print(\"  Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    KDkAT.load_state_dict(torch.load(drive_results_dir / f\"{dataset_name}_KDkAT_best.pth\", map_location=CONFIG[\"DEVICE\"]))\n",
        "    SAVED_MODELS_VISION[dataset_name][\"KDk+AT\"] = f\"{dataset_name}_KDkAT_best.pth\"\n",
        "\n",
        "    # Phase 4: KDk+AT+DP (KDk with Adversarial Training and Differential Privacy)\n",
        "    print(f\"\\n{dataset_name} – Phase 4: Training KDk+AT+DP (Adding Privacy)\")\n",
        "    KDkATDP = build_vfl_model_vision(num_classes)\n",
        "    KDkATDP.load_state_dict(torch.load(drive_results_dir / f\"{dataset_name}_KDkAT_best.pth\", map_location=CONFIG[\"DEVICE\"]))\n",
        "    opt = optim.AdamW(KDkATDP.parameters(), lr=hp[\"lr_student\"]/5, weight_decay=1e-4)\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        t0 = time.perf_counter()\n",
        "        train_loss, train_acc = train_epoch_KD_DP(KDkATDP, OA, tr_loader, opt, CONFIG, dataset_name, noise_multiplier=0.7)\n",
        "        val_loss, val_acc = evaluate_model(KDkATDP, te_loader, CONFIG, dataset_name=dataset_name)\n",
        "        _, rob_acc = evaluate_model(KDkATDP, te_loader, CONFIG, robust=True, dataset_name=dataset_name)\n",
        "        elapsed = time.perf_counter() - t0\n",
        "        print(f\"  Epoch {ep+1:02d}/{epochs} | Train Loss={train_loss:.4f} | Train ACC={train_acc:6.2f}% | Val Loss={val_loss:.4f} | Val ACC={val_acc:6.2f}% | Robust={rob_acc:6.2f}% | Time={elapsed:.1f}s\")\n",
        "\n",
        "    torch.save(KDkATDP.state_dict(), drive_results_dir / f\"{dataset_name}_KDkATDP_best.pth\")\n",
        "    SAVED_MODELS_VISION[dataset_name][\"KDk+AT+DP\"] = f\"{dataset_name}_KDkATDP_best.pth\"\n",
        "    print(f\"  Saved privacy-enhanced model.\")\n",
        "\n",
        "    del OA, KDk, KDkAT, KDkATDP, opt, sched\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Training completed for all datasets!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7RZ6t0gCZ0C",
        "outputId": "17a9edf1-1a7f-417d-b36c-15899f374eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Vision VFL Training with Optimizations\n",
            "======================================================================\n",
            "\n",
            "CIFAR100 – Phase 1: Training OA (Teacher)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:05<00:00, 11.91it/s, loss=3.7379]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 01/30 | Train Loss=4.1765 | Train ACC=  6.85% | Val Loss=3.9139 | Val ACC= 11.07% | Time=69.1s\n",
            "    → Best model saved (Val ACC: 11.07%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.39it/s, loss=3.2862]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 02/30 | Train Loss=3.5788 | Train ACC= 15.05% | Val Loss=3.2223 | Val ACC= 19.99% | Time=66.4s\n",
            "    → Best model saved (Val ACC: 19.99%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.44it/s, loss=2.8558]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 03/30 | Train Loss=3.2314 | Train ACC= 20.78% | Val Loss=2.9203 | Val ACC= 26.33% | Time=66.2s\n",
            "    → Best model saved (Val ACC: 26.33%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.38it/s, loss=2.8920]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 04/30 | Train Loss=2.9874 | Train ACC= 25.16% | Val Loss=2.7338 | Val ACC= 29.82% | Time=66.4s\n",
            "    → Best model saved (Val ACC: 29.82%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.31it/s, loss=2.4042]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 05/30 | Train Loss=2.7898 | Train ACC= 28.99% | Val Loss=2.3853 | Val ACC= 36.71% | Time=68.9s\n",
            "    → Best model saved (Val ACC: 36.71%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.25it/s, loss=2.9472]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 06/30 | Train Loss=2.6313 | Train ACC= 32.25% | Val Loss=2.2227 | Val ACC= 40.37% | Time=67.2s\n",
            "    → Best model saved (Val ACC: 40.37%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.20it/s, loss=2.6424]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 07/30 | Train Loss=2.4973 | Train ACC= 35.30% | Val Loss=2.1250 | Val ACC= 42.98% | Time=67.7s\n",
            "    → Best model saved (Val ACC: 42.98%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.51it/s, loss=2.6554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 08/30 | Train Loss=2.3666 | Train ACC= 38.21% | Val Loss=2.0228 | Val ACC= 45.33% | Time=66.1s\n",
            "    → Best model saved (Val ACC: 45.33%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:01<00:00, 12.72it/s, loss=2.2627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 09/30 | Train Loss=2.2539 | Train ACC= 41.04% | Val Loss=1.9195 | Val ACC= 47.46% | Time=64.8s\n",
            "    → Best model saved (Val ACC: 47.46%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:01<00:00, 12.65it/s, loss=2.0986]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 10/30 | Train Loss=2.1637 | Train ACC= 42.76% | Val Loss=1.8456 | Val ACC= 49.04% | Time=65.0s\n",
            "    → Best model saved (Val ACC: 49.04%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.41it/s, loss=2.0538]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 11/30 | Train Loss=2.0864 | Train ACC= 44.47% | Val Loss=1.8469 | Val ACC= 49.19% | Time=66.3s\n",
            "    → Best model saved (Val ACC: 49.19%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.52it/s, loss=2.1086]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 12/30 | Train Loss=1.9980 | Train ACC= 46.59% | Val Loss=1.7445 | Val ACC= 51.96% | Time=65.7s\n",
            "    → Best model saved (Val ACC: 51.96%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.56it/s, loss=1.4770]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 13/30 | Train Loss=1.9331 | Train ACC= 47.83% | Val Loss=1.6971 | Val ACC= 53.49% | Time=65.4s\n",
            "    → Best model saved (Val ACC: 53.49%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.56it/s, loss=1.9780]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 14/30 | Train Loss=1.8602 | Train ACC= 49.70% | Val Loss=1.6288 | Val ACC= 55.34% | Time=65.5s\n",
            "    → Best model saved (Val ACC: 55.34%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.48it/s, loss=1.9617]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30 | Train Loss=1.8036 | Train ACC= 51.18% | Val Loss=1.5889 | Val ACC= 55.81% | Time=65.9s\n",
            "    → Best model saved (Val ACC: 55.81%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.50it/s, loss=1.1716]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 16/30 | Train Loss=1.7369 | Train ACC= 52.61% | Val Loss=1.5305 | Val ACC= 57.26% | Time=65.7s\n",
            "    → Best model saved (Val ACC: 57.26%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.52it/s, loss=1.5942]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 17/30 | Train Loss=1.6863 | Train ACC= 54.03% | Val Loss=1.5032 | Val ACC= 58.26% | Time=65.6s\n",
            "    → Best model saved (Val ACC: 58.26%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.50it/s, loss=1.8492]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 18/30 | Train Loss=1.6295 | Train ACC= 55.55% | Val Loss=1.4818 | Val ACC= 58.93% | Time=65.8s\n",
            "    → Best model saved (Val ACC: 58.93%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.48it/s, loss=1.6554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 19/30 | Train Loss=1.5838 | Train ACC= 56.71% | Val Loss=1.4380 | Val ACC= 59.80% | Time=65.8s\n",
            "    → Best model saved (Val ACC: 59.80%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.53it/s, loss=1.8956]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 20/30 | Train Loss=1.5330 | Train ACC= 57.54% | Val Loss=1.4209 | Val ACC= 60.58% | Time=65.6s\n",
            "    → Best model saved (Val ACC: 60.58%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.45it/s, loss=1.5072]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 21/30 | Train Loss=1.4845 | Train ACC= 58.98% | Val Loss=1.4140 | Val ACC= 60.77% | Time=66.0s\n",
            "    → Best model saved (Val ACC: 60.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.42it/s, loss=1.1904]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 22/30 | Train Loss=1.4566 | Train ACC= 59.77% | Val Loss=1.3778 | Val ACC= 61.92% | Time=66.2s\n",
            "    → Best model saved (Val ACC: 61.92%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.31it/s, loss=1.6452]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 23/30 | Train Loss=1.4123 | Train ACC= 60.84% | Val Loss=1.3589 | Val ACC= 62.14% | Time=66.9s\n",
            "    → Best model saved (Val ACC: 62.14%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.37it/s, loss=1.3986]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 24/30 | Train Loss=1.3889 | Train ACC= 61.10% | Val Loss=1.3469 | Val ACC= 62.60% | Time=66.8s\n",
            "    → Best model saved (Val ACC: 62.60%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.56it/s, loss=1.3077]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 25/30 | Train Loss=1.3721 | Train ACC= 61.86% | Val Loss=1.3223 | Val ACC= 63.09% | Time=65.9s\n",
            "    → Best model saved (Val ACC: 63.09%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.58it/s, loss=1.5169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 26/30 | Train Loss=1.3404 | Train ACC= 62.72% | Val Loss=1.3230 | Val ACC= 63.37% | Time=65.7s\n",
            "    → Best model saved (Val ACC: 63.37%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.55it/s, loss=1.3067]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 27/30 | Train Loss=1.3227 | Train ACC= 62.99% | Val Loss=1.3127 | Val ACC= 63.28% | Time=65.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.45it/s, loss=1.2675]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 28/30 | Train Loss=1.3172 | Train ACC= 63.14% | Val Loss=1.3059 | Val ACC= 63.74% | Time=66.6s\n",
            "    → Best model saved (Val ACC: 63.74%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:02<00:00, 12.50it/s, loss=1.2079]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 29/30 | Train Loss=1.3198 | Train ACC= 63.19% | Val Loss=1.3071 | Val ACC= 63.54% | Time=66.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training OA: 100%|███████████████████████████████████| 781/781 [01:01<00:00, 12.65it/s, loss=1.1399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 30/30 | Train Loss=1.3063 | Train ACC= 63.53% | Val Loss=1.3028 | Val ACC= 63.70% | Time=65.5s\n",
            "\n",
            "CIFAR100 – Phase 2: Training KDk (Student)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.25it/s, loss=4.9032]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 01/30 | Train Loss=4.6743 | Train ACC= 12.19% | Val Loss=3.1229 | Val ACC= 24.07% | Time=67.7s\n",
            "    → Best model saved (Val ACC: 24.07%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.02it/s, loss=2.5575]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 02/30 | Train Loss=2.9458 | Train ACC= 25.99% | Val Loss=2.4112 | Val ACC= 37.33% | Time=68.5s\n",
            "    → Best model saved (Val ACC: 37.33%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:06<00:00, 11.72it/s, loss=1.8549]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 03/30 | Train Loss=2.1854 | Train ACC= 34.88% | Val Loss=2.1125 | Val ACC= 44.51% | Time=69.9s\n",
            "    → Best model saved (Val ACC: 44.51%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.09it/s, loss=1.6795]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 04/30 | Train Loss=1.7936 | Train ACC= 40.68% | Val Loss=1.9586 | Val ACC= 48.10% | Time=67.8s\n",
            "    → Best model saved (Val ACC: 48.10%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.11it/s, loss=1.2558]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 05/30 | Train Loss=1.5590 | Train ACC= 44.93% | Val Loss=1.8565 | Val ACC= 50.90% | Time=68.1s\n",
            "    → Best model saved (Val ACC: 50.90%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.14it/s, loss=1.3691]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 06/30 | Train Loss=1.4161 | Train ACC= 47.37% | Val Loss=1.7346 | Val ACC= 52.28% | Time=68.2s\n",
            "    → Best model saved (Val ACC: 52.28%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.16it/s, loss=1.3055]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 07/30 | Train Loss=1.3160 | Train ACC= 49.62% | Val Loss=1.6560 | Val ACC= 54.67% | Time=67.5s\n",
            "    → Best model saved (Val ACC: 54.67%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.18it/s, loss=1.2230]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 08/30 | Train Loss=1.2432 | Train ACC= 50.93% | Val Loss=1.5286 | Val ACC= 57.44% | Time=67.3s\n",
            "    → Best model saved (Val ACC: 57.44%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.24it/s, loss=1.1056]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 09/30 | Train Loss=1.1800 | Train ACC= 52.64% | Val Loss=1.5206 | Val ACC= 58.15% | Time=67.0s\n",
            "    → Best model saved (Val ACC: 58.15%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.28it/s, loss=1.1935]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 10/30 | Train Loss=1.1320 | Train ACC= 53.72% | Val Loss=1.4931 | Val ACC= 58.77% | Time=66.8s\n",
            "    → Best model saved (Val ACC: 58.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.21it/s, loss=1.0848]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 11/30 | Train Loss=1.0924 | Train ACC= 54.89% | Val Loss=1.4606 | Val ACC= 59.50% | Time=67.2s\n",
            "    → Best model saved (Val ACC: 59.50%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.16it/s, loss=1.0142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 12/30 | Train Loss=1.0562 | Train ACC= 55.67% | Val Loss=1.4510 | Val ACC= 59.85% | Time=68.0s\n",
            "    → Best model saved (Val ACC: 59.85%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.16it/s, loss=1.0569]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 13/30 | Train Loss=1.0282 | Train ACC= 56.36% | Val Loss=1.4205 | Val ACC= 60.24% | Time=68.0s\n",
            "    → Best model saved (Val ACC: 60.24%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.18it/s, loss=0.9316]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 14/30 | Train Loss=0.9970 | Train ACC= 57.37% | Val Loss=1.4078 | Val ACC= 60.64% | Time=67.3s\n",
            "    → Best model saved (Val ACC: 60.64%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.12it/s, loss=0.9554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30 | Train Loss=0.9707 | Train ACC= 57.76% | Val Loss=1.3923 | Val ACC= 60.76% | Time=67.6s\n",
            "    → Best model saved (Val ACC: 60.76%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.16it/s, loss=0.9435]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 16/30 | Train Loss=0.9461 | Train ACC= 59.10% | Val Loss=1.3699 | Val ACC= 61.90% | Time=67.5s\n",
            "    → Best model saved (Val ACC: 61.90%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.10it/s, loss=0.9034]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 17/30 | Train Loss=0.9267 | Train ACC= 59.35% | Val Loss=1.4070 | Val ACC= 61.18% | Time=67.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.02it/s, loss=0.8665]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 18/30 | Train Loss=0.9065 | Train ACC= 60.06% | Val Loss=1.3340 | Val ACC= 62.78% | Time=68.8s\n",
            "    → Best model saved (Val ACC: 62.78%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.15it/s, loss=0.8168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 19/30 | Train Loss=0.8927 | Train ACC= 60.36% | Val Loss=1.3264 | Val ACC= 62.61% | Time=68.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.14it/s, loss=0.8417]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 20/30 | Train Loss=0.8759 | Train ACC= 61.29% | Val Loss=1.2980 | Val ACC= 63.31% | Time=67.6s\n",
            "    → Best model saved (Val ACC: 63.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.08it/s, loss=1.1221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 21/30 | Train Loss=0.8622 | Train ACC= 61.42% | Val Loss=1.2939 | Val ACC= 63.48% | Time=67.9s\n",
            "    → Best model saved (Val ACC: 63.48%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.18it/s, loss=0.8849]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 22/30 | Train Loss=0.8477 | Train ACC= 61.80% | Val Loss=1.2859 | Val ACC= 63.88% | Time=67.3s\n",
            "    → Best model saved (Val ACC: 63.88%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.16it/s, loss=0.8224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 23/30 | Train Loss=0.8356 | Train ACC= 62.30% | Val Loss=1.2773 | Val ACC= 64.31% | Time=67.4s\n",
            "    → Best model saved (Val ACC: 64.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.19it/s, loss=0.9782]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 24/30 | Train Loss=0.8297 | Train ACC= 62.57% | Val Loss=1.2620 | Val ACC= 64.64% | Time=67.6s\n",
            "    → Best model saved (Val ACC: 64.64%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:03<00:00, 12.23it/s, loss=0.7624]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 25/30 | Train Loss=0.8197 | Train ACC= 62.94% | Val Loss=1.2674 | Val ACC= 64.15% | Time=67.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.17it/s, loss=0.6759]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 26/30 | Train Loss=0.8134 | Train ACC= 63.02% | Val Loss=1.2598 | Val ACC= 64.62% | Time=67.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.15it/s, loss=0.7362]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 27/30 | Train Loss=0.8072 | Train ACC= 63.29% | Val Loss=1.2524 | Val ACC= 64.43% | Time=67.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.10it/s, loss=0.7525]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 28/30 | Train Loss=0.7997 | Train ACC= 63.52% | Val Loss=1.2540 | Val ACC= 64.56% | Time=67.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:04<00:00, 12.14it/s, loss=0.8610]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 29/30 | Train Loss=0.8018 | Train ACC= 63.31% | Val Loss=1.2527 | Val ACC= 64.59% | Time=67.5s\n",
            "  Early stopping triggered.\n",
            "\n",
            "CIFAR100 – Phase 3: Training KDk+AT (Student + Adv Train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:14<00:00, 10.43it/s, loss=3.8552]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 01/30 | Train Loss=4.7304 | Train ACC= 10.88% | Val Loss=3.1423 | Val ACC= 24.03% | Robust= 21.54% | Time=83.7s\n",
            "    → Best model saved (Robust ACC: 21.54%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:14<00:00, 10.52it/s, loss=2.5387]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 02/30 | Train Loss=3.1011 | Train ACC= 22.79% | Val Loss=2.7389 | Val ACC= 32.06% | Robust= 29.08% | Time=83.5s\n",
            "    → Best model saved (Robust ACC: 29.08%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.36it/s, loss=2.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 03/30 | Train Loss=2.3211 | Train ACC= 30.74% | Val Loss=2.1736 | Val ACC= 42.30% | Robust= 39.00% | Time=83.9s\n",
            "    → Best model saved (Robust ACC: 39.00%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:14<00:00, 10.45it/s, loss=1.8836]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 04/30 | Train Loss=1.9528 | Train ACC= 35.47% | Val Loss=2.0889 | Val ACC= 44.92% | Robust= 41.21% | Time=83.6s\n",
            "    → Best model saved (Robust ACC: 41.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:14<00:00, 10.45it/s, loss=1.5425]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 05/30 | Train Loss=1.7128 | Train ACC= 39.19% | Val Loss=1.8663 | Val ACC= 50.02% | Robust= 45.71% | Time=83.7s\n",
            "    → Best model saved (Robust ACC: 45.71%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.36it/s, loss=1.5301]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 06/30 | Train Loss=1.5739 | Train ACC= 41.67% | Val Loss=1.7936 | Val ACC= 51.39% | Robust= 46.84% | Time=84.1s\n",
            "    → Best model saved (Robust ACC: 46.84%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.36it/s, loss=1.3815]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 07/30 | Train Loss=1.4603 | Train ACC= 42.68% | Val Loss=1.7997 | Val ACC= 51.95% | Robust= 47.24% | Time=84.5s\n",
            "    → Best model saved (Robust ACC: 47.24%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.34it/s, loss=1.2360]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 08/30 | Train Loss=1.3833 | Train ACC= 44.30% | Val Loss=1.6788 | Val ACC= 54.58% | Robust= 49.38% | Time=84.0s\n",
            "    → Best model saved (Robust ACC: 49.38%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.23it/s, loss=1.2026]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 09/30 | Train Loss=1.3234 | Train ACC= 45.85% | Val Loss=1.5826 | Val ACC= 56.50% | Robust= 51.48% | Time=85.3s\n",
            "    → Best model saved (Robust ACC: 51.48%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.35it/s, loss=1.3113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 10/30 | Train Loss=1.2691 | Train ACC= 46.90% | Val Loss=1.5403 | Val ACC= 56.80% | Robust= 51.51% | Time=84.2s\n",
            "    → Best model saved (Robust ACC: 51.51%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.40it/s, loss=1.1878]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 11/30 | Train Loss=1.2235 | Train ACC= 47.99% | Val Loss=1.5166 | Val ACC= 57.60% | Robust= 52.39% | Time=83.7s\n",
            "    → Best model saved (Robust ACC: 52.39%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:14<00:00, 10.44it/s, loss=1.1539]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 12/30 | Train Loss=1.1893 | Train ACC= 48.88% | Val Loss=1.4440 | Val ACC= 59.08% | Robust= 53.79% | Time=84.0s\n",
            "    → Best model saved (Robust ACC: 53.79%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.31it/s, loss=1.1965]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 13/30 | Train Loss=1.1567 | Train ACC= 49.28% | Val Loss=1.4382 | Val ACC= 59.82% | Robust= 53.73% | Time=84.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.32it/s, loss=1.2276]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 14/30 | Train Loss=1.1269 | Train ACC= 49.86% | Val Loss=1.4084 | Val ACC= 60.43% | Robust= 54.41% | Time=84.6s\n",
            "    → Best model saved (Robust ACC: 54.41%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.37it/s, loss=1.1285]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30 | Train Loss=1.0989 | Train ACC= 50.45% | Val Loss=1.4084 | Val ACC= 60.60% | Robust= 54.18% | Time=84.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.22it/s, loss=1.0635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 16/30 | Train Loss=1.0791 | Train ACC= 51.53% | Val Loss=1.3966 | Val ACC= 60.90% | Robust= 54.71% | Time=85.5s\n",
            "    → Best model saved (Robust ACC: 54.71%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.38it/s, loss=0.9992]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 17/30 | Train Loss=1.0589 | Train ACC= 51.95% | Val Loss=1.3751 | Val ACC= 60.94% | Robust= 55.26% | Time=84.7s\n",
            "    → Best model saved (Robust ACC: 55.26%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.26it/s, loss=1.0849]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 18/30 | Train Loss=1.0393 | Train ACC= 52.49% | Val Loss=1.3629 | Val ACC= 61.58% | Robust= 55.28% | Time=85.0s\n",
            "    → Best model saved (Robust ACC: 55.28%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.29it/s, loss=1.0412]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 19/30 | Train Loss=1.0166 | Train ACC= 52.64% | Val Loss=1.3302 | Val ACC= 62.08% | Robust= 55.80% | Time=85.1s\n",
            "    → Best model saved (Robust ACC: 55.80%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.17it/s, loss=1.0189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 20/30 | Train Loss=1.0021 | Train ACC= 53.29% | Val Loss=1.3192 | Val ACC= 62.34% | Robust= 56.28% | Time=85.7s\n",
            "    → Best model saved (Robust ACC: 56.28%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.22it/s, loss=1.1171]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 21/30 | Train Loss=0.9917 | Train ACC= 53.50% | Val Loss=1.3130 | Val ACC= 62.83% | Robust= 56.54% | Time=85.7s\n",
            "    → Best model saved (Robust ACC: 56.54%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.35it/s, loss=1.0091]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 22/30 | Train Loss=0.9761 | Train ACC= 53.86% | Val Loss=1.3099 | Val ACC= 62.72% | Robust= 56.81% | Time=83.9s\n",
            "    → Best model saved (Robust ACC: 56.81%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.34it/s, loss=0.8420]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 23/30 | Train Loss=0.9692 | Train ACC= 53.72% | Val Loss=1.2998 | Val ACC= 63.00% | Robust= 56.63% | Time=84.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:14<00:00, 10.44it/s, loss=0.9721]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 24/30 | Train Loss=0.9569 | Train ACC= 54.35% | Val Loss=1.2928 | Val ACC= 63.22% | Robust= 56.32% | Time=84.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.18it/s, loss=0.8346]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 25/30 | Train Loss=0.9508 | Train ACC= 54.61% | Val Loss=1.2953 | Val ACC= 63.13% | Robust= 56.72% | Time=85.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:15<00:00, 10.28it/s, loss=0.9665]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 26/30 | Train Loss=0.9451 | Train ACC= 54.79% | Val Loss=1.2845 | Val ACC= 63.35% | Robust= 57.00% | Time=85.4s\n",
            "    → Best model saved (Robust ACC: 57.00%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.15it/s, loss=0.9095]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 27/30 | Train Loss=0.9409 | Train ACC= 54.95% | Val Loss=1.2791 | Val ACC= 63.34% | Robust= 57.18% | Time=85.8s\n",
            "    → Best model saved (Robust ACC: 57.18%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.24it/s, loss=0.9281]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 28/30 | Train Loss=0.9313 | Train ACC= 55.35% | Val Loss=1.2779 | Val ACC= 63.50% | Robust= 57.08% | Time=85.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.25it/s, loss=0.9229]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 29/30 | Train Loss=0.9362 | Train ACC= 55.11% | Val Loss=1.2778 | Val ACC= 63.56% | Robust= 57.18% | Time=84.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD: 100%|███████████████████████████████████| 781/781 [01:16<00:00, 10.20it/s, loss=0.8680]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 30/30 | Train Loss=0.9312 | Train ACC= 55.24% | Val Loss=1.2746 | Val ACC= 63.52% | Robust= 57.20% | Time=85.9s\n",
            "    → Best model saved (Robust ACC: 57.20%)\n",
            "\n",
            "CIFAR100 – Phase 4: Training KDk+AT+DP (Adding Privacy)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:17<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 01/30 | Train Loss=1.0277 | Train ACC= 53.32% | Val Loss=1.3403 | Val ACC= 62.07% | Robust= 56.35% | Time=86.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:16<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 02/30 | Train Loss=1.0870 | Train ACC= 52.66% | Val Loss=1.3686 | Val ACC= 61.14% | Robust= 55.94% | Time=85.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:16<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 03/30 | Train Loss=1.1528 | Train ACC= 52.40% | Val Loss=1.3698 | Val ACC= 61.47% | Robust= 57.26% | Time=85.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:14<00:00, 10.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 04/30 | Train Loss=1.1576 | Train ACC= 53.22% | Val Loss=1.3875 | Val ACC= 60.81% | Robust= 57.41% | Time=83.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 05/30 | Train Loss=1.1645 | Train ACC= 53.70% | Val Loss=1.3804 | Val ACC= 60.83% | Robust= 57.74% | Time=84.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 06/30 | Train Loss=1.1802 | Train ACC= 53.58% | Val Loss=1.4103 | Val ACC= 60.29% | Robust= 57.61% | Time=84.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 07/30 | Train Loss=1.1878 | Train ACC= 53.62% | Val Loss=1.4074 | Val ACC= 60.85% | Robust= 57.73% | Time=84.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:16<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 08/30 | Train Loss=1.1812 | Train ACC= 53.86% | Val Loss=1.4056 | Val ACC= 60.66% | Robust= 57.91% | Time=84.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:17<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 09/30 | Train Loss=1.1871 | Train ACC= 54.19% | Val Loss=1.4207 | Val ACC= 60.28% | Robust= 57.74% | Time=86.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:16<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 10/30 | Train Loss=1.1871 | Train ACC= 54.27% | Val Loss=1.4160 | Val ACC= 60.48% | Robust= 58.18% | Time=84.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:14<00:00, 10.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 11/30 | Train Loss=1.2026 | Train ACC= 54.09% | Val Loss=1.4233 | Val ACC= 60.24% | Robust= 58.34% | Time=83.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:13<00:00, 10.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 12/30 | Train Loss=1.2042 | Train ACC= 54.16% | Val Loss=1.4342 | Val ACC= 59.94% | Robust= 58.40% | Time=83.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 13/30 | Train Loss=1.2102 | Train ACC= 54.62% | Val Loss=1.4357 | Val ACC= 59.89% | Robust= 58.35% | Time=83.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:14<00:00, 10.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 14/30 | Train Loss=1.2105 | Train ACC= 54.49% | Val Loss=1.4318 | Val ACC= 59.72% | Robust= 58.56% | Time=83.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:14<00:00, 10.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30 | Train Loss=1.2063 | Train ACC= 55.04% | Val Loss=1.4266 | Val ACC= 60.11% | Robust= 58.63% | Time=83.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:16<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 16/30 | Train Loss=1.2186 | Train ACC= 54.88% | Val Loss=1.4225 | Val ACC= 60.41% | Robust= 58.93% | Time=84.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 17/30 | Train Loss=1.2266 | Train ACC= 54.72% | Val Loss=1.4220 | Val ACC= 60.24% | Robust= 58.99% | Time=84.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 18/30 | Train Loss=1.2316 | Train ACC= 55.12% | Val Loss=1.4283 | Val ACC= 59.77% | Robust= 58.69% | Time=83.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 19/30 | Train Loss=1.2320 | Train ACC= 55.09% | Val Loss=1.4344 | Val ACC= 59.89% | Robust= 58.74% | Time=84.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 20/30 | Train Loss=1.2180 | Train ACC= 55.91% | Val Loss=1.4454 | Val ACC= 59.83% | Robust= 58.56% | Time=84.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 21/30 | Train Loss=1.2357 | Train ACC= 55.32% | Val Loss=1.4232 | Val ACC= 60.16% | Robust= 58.93% | Time=84.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 22/30 | Train Loss=1.2251 | Train ACC= 55.48% | Val Loss=1.4274 | Val ACC= 60.40% | Robust= 59.41% | Time=84.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 23/30 | Train Loss=1.2237 | Train ACC= 55.94% | Val Loss=1.4236 | Val ACC= 60.18% | Robust= 58.97% | Time=83.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 24/30 | Train Loss=1.2209 | Train ACC= 55.98% | Val Loss=1.4272 | Val ACC= 60.42% | Robust= 59.28% | Time=84.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 25/30 | Train Loss=1.2158 | Train ACC= 55.89% | Val Loss=1.4177 | Val ACC= 60.62% | Robust= 59.51% | Time=84.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 26/30 | Train Loss=1.2037 | Train ACC= 56.28% | Val Loss=1.4293 | Val ACC= 60.20% | Robust= 59.18% | Time=84.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:14<00:00, 10.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 27/30 | Train Loss=1.2086 | Train ACC= 56.16% | Val Loss=1.4132 | Val ACC= 60.47% | Robust= 59.30% | Time=83.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:14<00:00, 10.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 28/30 | Train Loss=1.2184 | Train ACC= 56.47% | Val Loss=1.4174 | Val ACC= 60.46% | Robust= 59.63% | Time=83.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 29/30 | Train Loss=1.2112 | Train ACC= 56.44% | Val Loss=1.4290 | Val ACC= 59.94% | Robust= 59.03% | Time=84.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training KD+AT+DP: 100%|██████████████████████████████████████████| 781/781 [01:15<00:00, 10.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 30/30 | Train Loss=1.2154 | Train ACC= 56.49% | Val Loss=1.4173 | Val ACC= 60.09% | Robust= 59.41% | Time=84.6s\n",
            "  Saved privacy-enhanced model.\n",
            "\n",
            "======================================================================\n",
            "Training completed for all datasets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 – FOCUSED EVALUATION: Analyzing CIFAR-100 Only\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, roc_auc_score, top_k_accuracy_score\n",
        "\n",
        "print(\"--- FOCUSED EVALUATION INITIATED ---\")\n",
        "print(\"Loading pre-trained CIFAR-10 models from Google Drive and running analysis.\")\n",
        "\n",
        "# Manually define the dictionary for only the completed Vision models\n",
        "SAVED_MODELS_VISION = {\n",
        "    \"CIFAR100\": {\n",
        "        \"OA\": \"CIFAR10_OA_best.pth\",\n",
        "        \"KDk\": \"CIFAR10_KDk_best.pth\",\n",
        "        \"KDk+AT\": \"CIFAR10_KDkAT_best.pth\",\n",
        "        \"KDk+AT+DP\": \"CIFAR10_KDkATDP_best.pth\"\n",
        "    }\n",
        "}\n",
        "\n",
        "drive_results_dir = Path(CONFIG[\"DRIVE_PATH\"]) / \"VFL_Results\" / \"VISION\"\n",
        "evaluation_results = []\n",
        "attack_modes = [\"passive\", \"direct\", \"active\", \"perturbed\"]\n",
        "\n",
        "for dataset_name, models in SAVED_MODELS_VISION.items():\n",
        "    loaders = VISION_LOADERS[dataset_name]\n",
        "    tr_loader, te_loader = loaders[\"train\"], loaders[\"test\"]\n",
        "    num_classes = loaders[\"num_classes\"]\n",
        "    hp = CONFIG[\"DATASET_HP\"][dataset_name]\n",
        "\n",
        "    for model_type, model_path in models.items():\n",
        "        print(f\"Evaluating {dataset_name} - {model_type}...\")\n",
        "        model = build_vfl_model_vision(num_classes)\n",
        "        model.load_state_dict(torch.load(drive_results_dir / model_path,\n",
        "                                         map_location=CONFIG[\"DEVICE\"]))\n",
        "        model.eval()\n",
        "\n",
        "        # Capture Top-1 and Top-5 accuracy\n",
        "        _, clean_acc_top1, clean_acc_top5 = evaluate_model(model, te_loader, CONFIG, dataset_name=dataset_name)\n",
        "        _, robust_acc_top1, robust_acc_top5 = evaluate_model(model, te_loader, CONFIG, robust=True, dataset_name=dataset_name)\n",
        "\n",
        "        # F1 & AUC\n",
        "        y_true, y_pred, y_probs = [], [], []\n",
        "        with torch.no_grad():\n",
        "            for (xa, xp), y in te_loader:\n",
        "                xa, xp, y = xa.to(CONFIG[\"DEVICE\"]), xp.to(CONFIG[\"DEVICE\"]), y.to(CONFIG[\"DEVICE\"])\n",
        "                logits = model(xa, xp)\n",
        "                probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "                preds = logits.argmax(1).cpu().numpy()\n",
        "                y_true.extend(y.cpu().numpy()); y_pred.extend(preds); y_probs.extend(probs)\n",
        "        y_true, y_pred, y_probs = np.array(y_true), np.array(y_pred), np.array(y_probs)\n",
        "        f1 = f1_score(y_true, y_pred, average='macro') * 100\n",
        "        auc = roc_auc_score(y_true, y_probs, multi_class='ovr') * 100\n",
        "\n",
        "        # Privacy Attacks\n",
        "        attack_results = {}\n",
        "        for attack in attack_modes:\n",
        "            a1, a5 = run_privacy_attack_vision_multimode(\n",
        "                model, tr_loader, te_loader, CONFIG, num_classes,\n",
        "                attack_type=attack, aux_batches_limit=4, attacker_epochs=2)\n",
        "            attack_results[attack] = {\"top1\": a1, \"top5\": a5}\n",
        "\n",
        "        pli = (1 - attack_results[\"passive\"][\"top1\"]/100.0) * (robust_acc_top1 / max(clean_acc_top1,1)) * 100\n",
        "\n",
        "        evaluation_results.append({\n",
        "            \"Dataset\": dataset_name,\n",
        "            \"Model\": model_type,\n",
        "            \"Clean ACC (Top-1 %)\": round(clean_acc_top1, 2),\n",
        "            \"Clean ACC (Top-5 %)\": round(clean_acc_top5, 2),\n",
        "            \"Robust ACC (Top-1 %)\": round(robust_acc_top1, 2),\n",
        "            \"Robust ACC (Top-5 %)\": round(robust_acc_top5, 2),\n",
        "            \"F1 (%)\": round(f1, 2),\n",
        "            \"AUC (%)\": round(auc, 2),\n",
        "            \"ASR_passive (Top-1 %)\": round(attack_results[\"passive\"][\"top1\"], 2),\n",
        "            \"ASR_passive (Top-5 %)\": round(attack_results[\"passive\"][\"top5\"], 2),\n",
        "            \"ASR_direct (Top-1 %)\": round(attack_results[\"direct\"][\"top1\"], 2),\n",
        "            \"ASR_direct (Top-5 %)\": round(attack_results[\"direct\"][\"top5\"], 2),\n",
        "            \"ASR_active (Top-1 %)\": round(attack_results[\"active\"][\"top1\"], 2),\n",
        "            \"ASR_active (Top-5 %)\": round(attack_results[\"active\"][\"top5\"], 2),\n",
        "            \"ASR_perturbed (Top-1 %)\": round(attack_results[\"perturbed\"][\"top1\"], 2),\n",
        "            \"ASR_perturbed (Top-5 %)\": round(attack_results[\"perturbed\"][\"top5\"], 2),\n",
        "            \"Privacy Leakage Index\": round(pli, 2)\n",
        "        })\n",
        "\n",
        "eval_df = pd.DataFrame(evaluation_results)\n",
        "eval_path = drive_results_dir / \"evaluation_results_cifar10_only.csv\"\n",
        "eval_df.to_csv(eval_path, index=False)\n",
        "display(eval_df)\n",
        "print(f\"\\nEvaluation complete for CIFAR-10. Results saved to: {eval_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "HTnBQs8oGBwK",
        "outputId": "54b6403b-48bb-4c25-b358-4d6b9a7d8a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FOCUSED EVALUATION INITIATED ---\n",
            "Loading pre-trained CIFAR-100 models from Google Drive and running analysis.\n",
            "Evaluating CIFAR100 - OA...\n",
            "Evaluating CIFAR100 - KDk...\n",
            "Evaluating CIFAR100 - KDk+AT...\n",
            "Evaluating CIFAR100 - KDk+AT+DP...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Dataset      Model  Clean ACC (Top-1 %)  Clean ACC (Top-5 %)  \\\n",
              "0  CIFAR100         OA                63.74                87.96   \n",
              "1  CIFAR100        KDk                64.64                88.96   \n",
              "2  CIFAR100     KDk+AT                63.52                88.55   \n",
              "3  CIFAR100  KDk+AT+DP                60.09                86.34   \n",
              "\n",
              "   Robust ACC (Top-1 %)  Robust ACC (Top-5 %)  F1 (%)  AUC (%)  \\\n",
              "0                 39.71                 74.58   63.58    98.58   \n",
              "1                 42.03                 76.67   64.36    98.69   \n",
              "2                 57.20                 85.25   63.27    98.64   \n",
              "3                 59.41                 85.81   59.82    98.34   \n",
              "\n",
              "   ASR_passive (Top-1 %)  ASR_passive (Top-5 %)  ASR_direct (Top-1 %)  \\\n",
              "0                   4.75                  14.89                  2.09   \n",
              "1                   2.52                  10.08                  1.94   \n",
              "2                   2.55                  10.20                  1.65   \n",
              "3                   2.82                  10.26                  1.99   \n",
              "\n",
              "   ASR_direct (Top-5 %)  ASR_active (Top-1 %)  ASR_active (Top-5 %)  \\\n",
              "0                  9.07                  7.31                 20.57   \n",
              "1                  8.11                  4.44                 14.70   \n",
              "2                  7.53                  6.68                 17.94   \n",
              "3                  6.77                  3.18                 12.38   \n",
              "\n",
              "   ASR_perturbed (Top-1 %)  ASR_perturbed (Top-5 %)  Privacy Leakage Index  \n",
              "0                     4.52                    14.73                  59.34  \n",
              "1                     2.63                    11.07                  63.38  \n",
              "2                     3.36                     9.84                  87.75  \n",
              "3                     3.11                    11.06                  96.08  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d00de33a-e196-463d-871b-bc453c0b45ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Model</th>\n",
              "      <th>Clean ACC (Top-1 %)</th>\n",
              "      <th>Clean ACC (Top-5 %)</th>\n",
              "      <th>Robust ACC (Top-1 %)</th>\n",
              "      <th>Robust ACC (Top-5 %)</th>\n",
              "      <th>F1 (%)</th>\n",
              "      <th>AUC (%)</th>\n",
              "      <th>ASR_passive (Top-1 %)</th>\n",
              "      <th>ASR_passive (Top-5 %)</th>\n",
              "      <th>ASR_direct (Top-1 %)</th>\n",
              "      <th>ASR_direct (Top-5 %)</th>\n",
              "      <th>ASR_active (Top-1 %)</th>\n",
              "      <th>ASR_active (Top-5 %)</th>\n",
              "      <th>ASR_perturbed (Top-1 %)</th>\n",
              "      <th>ASR_perturbed (Top-5 %)</th>\n",
              "      <th>Privacy Leakage Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CIFAR100</td>\n",
              "      <td>OA</td>\n",
              "      <td>63.74</td>\n",
              "      <td>87.96</td>\n",
              "      <td>39.71</td>\n",
              "      <td>74.58</td>\n",
              "      <td>63.58</td>\n",
              "      <td>98.58</td>\n",
              "      <td>4.75</td>\n",
              "      <td>14.89</td>\n",
              "      <td>2.09</td>\n",
              "      <td>9.07</td>\n",
              "      <td>7.31</td>\n",
              "      <td>20.57</td>\n",
              "      <td>4.52</td>\n",
              "      <td>14.73</td>\n",
              "      <td>59.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CIFAR100</td>\n",
              "      <td>KDk</td>\n",
              "      <td>64.64</td>\n",
              "      <td>88.96</td>\n",
              "      <td>42.03</td>\n",
              "      <td>76.67</td>\n",
              "      <td>64.36</td>\n",
              "      <td>98.69</td>\n",
              "      <td>2.52</td>\n",
              "      <td>10.08</td>\n",
              "      <td>1.94</td>\n",
              "      <td>8.11</td>\n",
              "      <td>4.44</td>\n",
              "      <td>14.70</td>\n",
              "      <td>2.63</td>\n",
              "      <td>11.07</td>\n",
              "      <td>63.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CIFAR100</td>\n",
              "      <td>KDk+AT</td>\n",
              "      <td>63.52</td>\n",
              "      <td>88.55</td>\n",
              "      <td>57.20</td>\n",
              "      <td>85.25</td>\n",
              "      <td>63.27</td>\n",
              "      <td>98.64</td>\n",
              "      <td>2.55</td>\n",
              "      <td>10.20</td>\n",
              "      <td>1.65</td>\n",
              "      <td>7.53</td>\n",
              "      <td>6.68</td>\n",
              "      <td>17.94</td>\n",
              "      <td>3.36</td>\n",
              "      <td>9.84</td>\n",
              "      <td>87.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CIFAR100</td>\n",
              "      <td>KDk+AT+DP</td>\n",
              "      <td>60.09</td>\n",
              "      <td>86.34</td>\n",
              "      <td>59.41</td>\n",
              "      <td>85.81</td>\n",
              "      <td>59.82</td>\n",
              "      <td>98.34</td>\n",
              "      <td>2.82</td>\n",
              "      <td>10.26</td>\n",
              "      <td>1.99</td>\n",
              "      <td>6.77</td>\n",
              "      <td>3.18</td>\n",
              "      <td>12.38</td>\n",
              "      <td>3.11</td>\n",
              "      <td>11.06</td>\n",
              "      <td>96.08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d00de33a-e196-463d-871b-bc453c0b45ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d00de33a-e196-463d-871b-bc453c0b45ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d00de33a-e196-463d-871b-bc453c0b45ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68d48cfd-1122-4d7b-a368-472cbcb19a1d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68d48cfd-1122-4d7b-a368-472cbcb19a1d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68d48cfd-1122-4d7b-a368-472cbcb19a1d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_eb312f30-e0a3-46c0-8f22-684e519341f7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eval_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb312f30-e0a3-46c0-8f22-684e519341f7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('eval_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eval_df",
              "summary": "{\n  \"name\": \"eval_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CIFAR100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"KDk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clean ACC (Top-1 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.997971888357457,\n        \"min\": 60.09,\n        \"max\": 64.64,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          64.64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clean ACC (Top-5 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1506918208915269,\n        \"min\": 86.34,\n        \"max\": 88.96,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          88.96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Robust ACC (Top-1 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.150738478882541,\n        \"min\": 39.71,\n        \"max\": 59.41,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          42.03\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Robust ACC (Top-5 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.786474891215434,\n        \"min\": 74.58,\n        \"max\": 85.81,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          76.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0113076177783773,\n        \"min\": 59.82,\n        \"max\": 64.36,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          64.36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15499999999999778,\n        \"min\": 98.34,\n        \"max\": 98.69,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          98.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_passive (Top-1 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0685504199615479,\n        \"min\": 2.52,\n        \"max\": 4.75,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_passive (Top-5 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.356188659679017,\n        \"min\": 10.08,\n        \"max\": 14.89,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_direct (Top-1 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1889223826513594,\n        \"min\": 1.65,\n        \"max\": 2.09,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_direct (Top-5 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9700859068488042,\n        \"min\": 6.77,\n        \"max\": 9.07,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_active (Top-1 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9266962223799922,\n        \"min\": 3.18,\n        \"max\": 7.31,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_active (Top-5 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5967983448246494,\n        \"min\": 12.38,\n        \"max\": 20.57,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          14.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_perturbed (Top-1 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8026830009412182,\n        \"min\": 2.63,\n        \"max\": 4.52,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_perturbed (Top-5 %)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.116955360889785,\n        \"min\": 9.84,\n        \"max\": 14.73,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          11.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Privacy Leakage Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.041279287604116,\n        \"min\": 59.34,\n        \"max\": 96.08,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          63.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation complete for CIFAR-10. Results saved to: /content/VFL_Results/VISION/evaluation_results_cifar10_only.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8f4FHAfq5VO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}